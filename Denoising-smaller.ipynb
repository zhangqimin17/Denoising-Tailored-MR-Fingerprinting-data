{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligent denoising of Tailored MR Fingerprinting data (with smaller training set and epochs)\n",
    "\n",
    "## Qimin Zhang and Weiwei Qi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import l1\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import torch\n",
    "\n",
    "from keras import models\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "# from dfply import *\n",
    "\n",
    "torch.manual_seed(4460)\n",
    "np.random.seed(4460)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read data and explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = scipy.io.loadmat('./data/xtrain.mat')\n",
    "ytrain = scipy.io.loadmat('./data/ytrain.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(xtrain['TMRF_T2']) == len(ytrain['GS_T2'])\n",
    "print('The sample size is', len(xtrain['TMRF_T2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first image in xtrain\n",
    "plt.imshow(xtrain['TMRF_T2'][1])    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first image in ytrain\n",
    "plt.imshow(ytrain['GS_T2'][1])    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With crop\n",
    "\n",
    "print(ytrain['GS_T2'][1][0:224,0:224].shape)\n",
    "plt.imshow(ytrain['GS_T2'][1][0:224,0:224])    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(pretrained_weights=None, input_size=(224, 224, 1)):\n",
    "    inputs = Input(input_size)\n",
    "    # conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    # conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    # pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(drop5))\n",
    "    merge6 = concatenate([drop4, up6], axis=3)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(conv6))\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    # conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    # conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "\n",
    "    conv7 = Conv2D(256, 1, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 1, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "\n",
    "    # up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "    #     UpSampling2D(size=(2, 2))(conv7))\n",
    "\n",
    "    # up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "    #     UpSampling2D(size=(2, 2))(conv7))\n",
    "    up8 = Conv2D(128, 1, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(conv7))\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "\n",
    "    # conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 1, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    # conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "    conv8 = Conv2D(128, 1, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "\n",
    "    # up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "    #     UpSampling2D(size=(2, 2))(conv8))\n",
    "    # merge9 = concatenate([conv1, up9], axis=3)\n",
    "    # conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
    "    # conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    # conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "\n",
    "\n",
    "    # conv10 = Conv2D(1, 1, kernel_regularizer=l1(0.0001))(conv8)\n",
    "    conv10 = Conv2D(1, 1)(conv8)\n",
    "\n",
    "    model = Model(input=inputs, output=conv10)\n",
    "    model.compile(optimizer=Adam(lr=1e-4), loss='mse',  metrics=['mae', 'mse'])\n",
    "    print(model.summary())\n",
    "\n",
    "    if (pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = np.random.choice(len(xtrain['TMRF_T2']), 10, replace=False)\n",
    "\n",
    "xtest = xtrain['TMRF_T2'][random_index]\n",
    "ytest = ytrain['GS_T2'][random_index]\n",
    "\n",
    "xtrain = np.delete(xtrain['TMRF_T2'], random_index, axis=0)\n",
    "ytrain = np.delete(ytrain['GS_T2'], random_index, axis=0)\n",
    "\n",
    "xtrain = np.reshape(xtrain, [10, 225, 225, 1])\n",
    "ytrain = np.reshape(ytrain, [10, 225, 225, 1])\n",
    "xtest = np.reshape(xtest, [10, 225, 225, 1])\n",
    "ytest = np.reshape(ytest, [10, 225, 225, 1])\n",
    "\n",
    "xtrain = xtrain[:, 0:224, 0:224, :]\n",
    "ytrain = ytrain[:, 0:224, 0:224, :]\n",
    "xtest = xtest[:, 0:224, 0:224, :]\n",
    "ytest = ytest[:, 0:224, 0:224, :]\n",
    "\n",
    "print(len(xtrain))\n",
    "print(len(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define paths\n",
    "checkpoint_path = \"unet_weights_{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "# Define model hyperparameters\n",
    "EPOCHS = 20\n",
    "SPEREPOCH = 20\n",
    "\n",
    "\n",
    "# Setup definitions for display\n",
    "def plot_history(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error')\n",
    "    plt.plot(hist['epoch'], hist['loss'],\n",
    "             label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['mae'],\n",
    "             label='Val Error')\n",
    "    plt.ylim([0, 500])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "model = unet()\n",
    "\n",
    "# plot_model(model, to_file='model_plot.png')\n",
    "\n",
    "# model_checkpoint = ModelCheckpoint('unet_pepa.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "# cp_callback =  ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1,save_best_only=True)\n",
    "# cp_callback = ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=1)\n",
    "\n",
    "# cp_callback = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=1, save_best_only=False,\n",
    "#                               save_weights_only=True, mode='auto', period=1)\n",
    "\n",
    "cp_callback = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=1, save_best_only=False,\n",
    "                              save_weights_only=True, mode='auto', period=10)\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', baseline=0.4)\n",
    "\n",
    "callbacks_list = [cp_callback, es]\n",
    "history = model.fit(\n",
    "    xtrain, ytrain, steps_per_epoch=SPEREPOCH,\n",
    "    epochs=EPOCHS, callbacks=callbacks_list, verbose=2)\n",
    "print('Training done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_save = {'loss': history.history['loss'], 'mae': history.history['mae'], 'mse': history.history['mse']}\n",
    "sio.savemat('./history_invcor.mat', history_save)\n",
    "plot_history(history)\n",
    "\n",
    "# VISUALIZATION\n",
    "plot_model(model, to_file='model_plot_invcor.png', show_shapes=True, show_layer_names=True)\n",
    "# layer_outputs = [layer.output for layer in model.layers[:1]]\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "\n",
    "activation_model = models.Model(inputs=model.input,\n",
    "                                outputs=layer_outputs)  # Creates a model that will return these outputs, given the model input\n",
    "activations = activation_model.predict(xtest_vis)\n",
    "\n",
    "first_layer_activation = activations[29]\n",
    "print(first_layer_activation.shape)\n",
    "plt.matshow(first_layer_activation[0, :, :, 0], cmap='viridis')\n",
    "plt.show()\n",
    "\n",
    "dictOfactivations = {'Layer'+str(i): activations[i] for i in range(0, len(activations))}\n",
    "sio.savemat('./Lactivations_invcor.mat', dictOfactivations)\n",
    "\n",
    "# TESTING\n",
    "ypred = model.predict(xtest, verbose=1)\n",
    "result = {'ypred_invcor': ypred, 'ytrain_deblur': ytrain}\n",
    "sio.savemat('./SVPSF_128_invcor.mat', result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 BMEN4460",
   "language": "python",
   "name": "bmen4460"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
